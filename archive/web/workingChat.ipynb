{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from flask import Flask, request, render_template\n",
    "from twilio.twiml.messaging_response import MessagingResponse\n",
    "import openai\n",
    "import os\n",
    "from google.auth import _service_account_info\n",
    "from google.cloud import storage\n",
    "import google.auth\n",
    "from google.cloud import storage\n",
    "from google.oauth2.service_account import Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "completion = openai.Completion()\n",
    "\n",
    "start_sequence = \"\\nAI:\"\n",
    "restart_sequence = \"\\nHuman: \"\n",
    "# session_prompt = \"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\"\n",
    "\n",
    "session_prompt = \"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\\nHuman: Hello, who are you?\\nAI: I am an AI created by OpenAI. How can I help you today?\\nHuman: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "app.config['SECRET_KEY'] = '323434'\n",
    "\n",
    "model = \"text-davinci-003\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_log(response):\n",
    "    \"\"\"\n",
    "    Logs a conversation to a Google Cloud Storage bucket and returns the updated log.\n",
    "\n",
    "    Args:\n",
    "        response (str): A string containing a single entry to be added to the log\n",
    "\n",
    "    Returns:\n",
    "        str: The updated conversation log\n",
    "    \"\"\"\n",
    "    # Load Google Cloud Storage credentials from environment variables\n",
    "    credentials = Credentials.from_service_account_file('gpt-pdsbot-svc.json')\n",
    "\n",
    "    # Connect to the GCS bucket\n",
    "    client = storage.Client(project='gpt-pdsbot', credentials=credentials)\n",
    "    bucket = client.bucket(\"pds_ai_chat_logs\")\n",
    "\n",
    "    # Download the current log from the bucket and convert it to a string\n",
    "    blob = bucket.get_blob(\"chat_log.txt\")\n",
    "    chat_log = blob.download_as_string().decode(\"utf-8\")\n",
    "\n",
    "    # Append the new entry to the log and upload it to the bucket\n",
    "    new_discussion = response\n",
    "    chat_log += new_discussion\n",
    "    blob.upload_from_string(chat_log.encode(\"utf-8\"))\n",
    "\n",
    "    # Return the updated conversation log\n",
    "    return chat_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also want to print the most three recent conversations\n",
    "def print_recent_conversations():\n",
    "    \"\"\"\n",
    "    Prints the most recent 3 conversations from the chat log.\n",
    "    \"\"\"\n",
    "    # Load Google Cloud Storage credentials from environment variables\n",
    "    credentials = Credentials.from_service_account_file('../gpt-pdsbot-svc.json')\n",
    "\n",
    "    # Connect to the GCS bucket\n",
    "    client = storage.Client(project='gpt-pdsbot', credentials=credentials)\n",
    "    bucket = client.bucket(\"pds_ai_chat_logs\")\n",
    "\n",
    "    # Download the current log from the bucket and convert it to a string\n",
    "    blob = bucket.get_blob(\"chat_log.txt\")\n",
    "    chat_log = blob.download_as_string().decode(\"utf-8\")\n",
    "\n",
    "    # Split the log into a list of entries\n",
    "    log_entries = chat_log.split(\"\\n\")\n",
    "\n",
    "    # Print the most recent 3 entries\n",
    "    print(\"Most recent conversations:\")\n",
    "    for i in range(1, 4):\n",
    "        print(log_entries[-i]) \n",
    "        \n",
    "        # Print a separator between entries\n",
    "        print(\"-----\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_chat(question, chat_log=add_log):\n",
    "    \"\"\"\n",
    "    Generates a response to a user's question using the OpenAI API and a specified language model.\n",
    "    Logs the user's question and the generated response to a chat log.\n",
    "\n",
    "    Args:\n",
    "        question (str): The user's input question\n",
    "        chat_log (function): A function that logs the conversation to a file or database\n",
    "\n",
    "    Returns:\n",
    "        str: The AI's generated response to the user's question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the prompt text by concatenating the chat log, question, and sequence markers\n",
    "    prompt_text = f'{chat_log}{restart_sequence}{question}{start_sequence}'\n",
    "    \n",
    "    # Generate the AI's response using the OpenAI API and the specified model\n",
    "    response = openai.Completion.create(\n",
    "        model=model,                # Specify the language model to use\n",
    "        prompt=prompt_text,         # Provide the starting text prompt for the model\n",
    "        temperature=0.9,            # Set the level of randomness in the generated text\n",
    "        max_tokens=150,             # Limit the length of the generated text\n",
    "        top_p=1,                    # Control the probability threshold for word selection\n",
    "        frequency_penalty=0,        # Discourage the model from repeating certain words\n",
    "        presence_penalty=0.6,       # Discourage the model from repeating phrases\n",
    "        stop=[\" Human:\", \" AI:\"]    # Set stopping conditions for the generated text\n",
    "    )\n",
    "    \n",
    "    # Extract the generated text from the OpenAI API response and convert it to a string\n",
    "    story = str(response['choices'][0]['text'])\n",
    "    \n",
    "    # Convert the question and response to strings and log them in a dictionary\n",
    "    submission = str(question)\n",
    "    response = str(story)\n",
    "    sess_dict = {\n",
    "        \"Submission\": submission,\n",
    "        \"Response\": response\n",
    "    }       \n",
    "    \n",
    "    # Add the dictionary to the chat log and return the generated response\n",
    "    sess_dict = str(sess_dict)\n",
    "    chat_log(sess_dict)\n",
    "    print(sess_dict)\n",
    "    \n",
    "    #For this format I prefer visually to not print the story, so I don't return it\n",
    "    # return story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Submission': 'What do you think is the best Naughty by Nature song?', 'Response': ' Naughty by Nature is most known for the song \"O.P.P.,\" from their 1991 self-titled album. Other popular songs from the group include \"Hip Hop Hooray,\" \"Feel Me Flow,\" and \"Everything\\'s Gonna Be Alright.\"'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ask_chat(\"What do you think is the best Naughty by Nature song?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a web app using Flask\n",
    "# app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "# # Create a route for the home page\n",
    "# @app.route('/')\n",
    "# def home():\n",
    "#     name = 'John'\n",
    "#     return render_template('home.html', name=name)\n",
    "\n",
    "    \n",
    "\n",
    "# # Create a route for the chat page  \n",
    "# @app.route(\"/chat\")\n",
    "# def chat():\n",
    "#     return render_template(\"chat.html\")\n",
    "\n",
    "# # Create a route for the chatbot    \n",
    "# @app.route(\"/get\")\n",
    "# def get_bot_response():\n",
    "#     userText = request.args.get('msg')\n",
    "#     return str(ask_chat(userText))\n",
    "\n",
    "# # Run the web app\n",
    "# if __name__ == \"__main__\":\n",
    "#     app.run()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb_venv",
   "language": "python",
   "name": "cb_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1361d2bad0f0fcc258197b60de7d99f8f216751f79c1093a910cda9611a123f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
