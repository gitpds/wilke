{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statement and loading environment variables\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from google.cloud import storage \n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User set variables\n",
    "\n",
    "user = '5037547138'\n",
    "\n",
    "\n",
    "bot_name = 'wilke'\n",
    "# TODO - Can be used to start with a baseline prompt, then customize the bot on creation with the prompt. \n",
    "\n",
    "# prompt = TODO - add prompt, allowing the customerization of the bot on creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard variables and formulas for GCP\n",
    "\n",
    "working_dir = pathlib.Path.cwd()\n",
    "bucket_name = 'gpt_chat_logs'\n",
    "chat_file_folder = working_dir.joinpath('chat_logs')\n",
    "file_path = chat_file_folder.joinpath('{}_{}_chat.json'.format(user, bot_name))\n",
    "file_name = ('{}_{}_chat.json'.format(user, bot_name))\n",
    "STORAGE_CLASSES = ('STANDARD', 'NEARLINE', 'COLDLINE', 'ARCHIVE')\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for working with Google Cloud Storage\n",
    "\n",
    "class GCStorage:\n",
    "    def __init__(self, storage_client):\n",
    "        self.client = storage_client\n",
    "\n",
    "    # Create a bucket\n",
    "    def create_bucket(self, bucket_name, storage_class, bucket_location='US'):\n",
    "        bucket = self.client.bucket(bucket_name)\n",
    "        bucket.storage_class = storage_class\n",
    "        return self.client.create_bucket(bucket, bucket_location)        \n",
    "\n",
    "    # Get a bucket\n",
    "    def get_bucket(self, bucket_name):\n",
    "        return self.client.get_bucket(bucket_name)\n",
    "\n",
    "    # List all buckets\n",
    "    def list_buckets(self):\n",
    "        buckets = self.client.list_buckets()\n",
    "        return [bucket.name for bucket in buckets]\n",
    "\n",
    "    # Upload a file to a bucket\n",
    "    def upload_file(self, bucket, blob_destination, file_path):\n",
    "        blob = bucket.blob(blob_destination)\n",
    "        blob.upload_from_filename(file_path, content_type='application/json')\n",
    "        return blob\n",
    "\n",
    "    # List all blobs in a bucket\n",
    "    def list_blobs(self, bucket_name):\n",
    "        return self.client.list_blobs(bucket_name)\n",
    "    \n",
    "    def download_blob(self, bucket_name, blob_name, file_path):\n",
    "        bucket = self.client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob.download_to_filename(file_path)\n",
    "        return blob\n",
    "    \n",
    "    \n",
    "    def load_file(self, bucket, blob_name):\n",
    "        bucket = storage_client.get_bucket(bucket)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        data = json.loads(blob.download_as_string(client=None))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the GCP storage class and loading the chat log file\n",
    "gcs = GCStorage(storage_client)\n",
    "CHAT_LOG_FILE = gcs.load_file(bucket_name, file_name)\n",
    "chat_log = CHAT_LOG_FILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bucket if it doesn't exist and chat log management functions\n",
    "\n",
    "def get_or_create_bucket(bucket_name):\n",
    "    if not bucket_name in gcs.list_buckets():\n",
    "        gcs.create_bucket(bucket_name, STORAGE_CLASSES[0])\n",
    "    else:\n",
    "        gcs.get_bucket(bucket_name)\n",
    "        \n",
    "        \n",
    "# Create a new chat log file in the local chat_logs folder\n",
    "def create_chat_log_file(user, bot_name):\n",
    "    # TODO This function requires me to manually load the starting json \n",
    "    # Opportunity to integrate the startup exeperience while solving this manual operation\n",
    "    filename = f'{user}_{bot_name}_chat.json'\n",
    "    file_path = chat_file_folder.joinpath(filename)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write('')\n",
    "    return file_path\n",
    "\n",
    "# upload the chat log file to the bucket\n",
    "def upload_chat_log_file(bucket_name, file_path):\n",
    "    name = f'{user}_{bot_name}_chat.json'\n",
    "    filename = name\n",
    "    bucket = gcs.get_bucket(bucket_name)\n",
    "    blob = gcs.upload_file(bucket, filename, file_path)\n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "## Called functions that will work correctly\n",
    "\n",
    "# create_chat_log_file(user, bot_name)\n",
    "# upload_chat_log_file(bucket_name, file_path)\n",
    "# data = gcs.load_file(bucket_name, file_name)\n",
    "# print(data  )\n",
    "\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "# Test function to make sure the model is returning a response\n",
    "\n",
    "# completion = openai.ChatCompletion.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages = [\n",
    "#             {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#             {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "#             {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "#             {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "#              ] \n",
    "#             )\n",
    "\n",
    "# print(completion.choices[0].message)\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle the chat log and return the response\n",
    "\n",
    "def text(question):\n",
    "    bucket = gcs.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(file_name)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "\n",
    "\n",
    "        messages = chat_log)\n",
    "    question = str(question)\n",
    "    return_response = (response)['choices'][0]['message']['content']\n",
    "    \n",
    "    new_log = chat_log\n",
    "    new_log.append({\"role\": \"user\", \"content\": question})\n",
    "    new_log.append({\"role\": \"assistant\", \"content\": return_response})\n",
    "    \n",
    "    json_data = json.dumps(new_log, indent=4)\n",
    "    \n",
    "    # print(json_data)\n",
    "    # print(new_log)\n",
    "\n",
    "    blob.upload_from_string(json_data, content_type='application/json')\n",
    "\n",
    "    return return_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize if I gave you the impression that I am not working. I am functioning properly and ready to assist you with any questions or tasks you have. How may I assist you today?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Question\n",
    "text('Are you going to finally work?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text for conversation generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gpt",
   "language": "python",
   "name": "env_gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
